\documentclass[11pt]{article}
\usepackage{fullpage}
\usepackage{fancyhdr}
\usepackage{epsfig}
\usepackage{multienum}
\usepackage{algorithm}
\usepackage[noend]{algorithmic}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{ifsym}

\newtheorem{lemma}{Lemma}
\newtheorem*{lem}{Lemma}
\newtheorem{definition}{Definition}
\newtheorem*{definition*}{Definition}
\newtheorem{notation}{Notation}
\newtheorem*{claim}{Claim}
\newtheorem*{fclaim}{False Claim}
\newtheorem{observation}{Observation}
\newtheorem{conjecture}[lemma]{Conjecture}
\newtheorem{theorem}[lemma]{Theorem}
\newtheorem{corollary}[lemma]{Corollary}
\newtheorem{proposition}[lemma]{Proposition}
\newtheorem*{rt}{Running Time}

\def\P{\ensuremath{\mathcal{P}}}
\def\s{\ensuremath{{\bf s}}}
\def\p{\ensuremath{{\bf p}}}
\def\opt{\ensuremath{\textsc{opt}}}

\textheight=8.6in
\setlength{\textwidth}{6.44in}
\addtolength{\headheight}{\baselineskip} 
% enumerate uses a., b., c., ...
\renewcommand{\labelenumi}{\bf \alph{enumi}.}
% Sets the style for fancy pages (namely, all but first page)
\pagestyle{fancy}
\fancyhf{}
\renewcommand{\headrulewidth}{0.0pt}
\renewcommand{\footrulewidth}{0.4pt}
% Changes style of plain pages (namely, the first page)
\fancypagestyle{plain}{
  \fancyhf{}
  \renewcommand\headrulewidth{0pt}
  \renewcommand\footrulewidth{0.4pt}
  \renewcommand{\headrule}{}
}

\title{Screeps Lite: An Environment of Exploration, Emergence, Greediness, and Sabotage}
\author{Eren Guendelsberger, Jake Israel, and James Capuder}
\date{Spring 2017}

\begin{document}
\maketitle
\thispagestyle{plain}

\begin{abstract}
Insert abstract here.
\end{abstract}

\section{Introduction}

	The primary goal of this project was to explore the phenomenon of emerging intelligence in multiagent systems. Using an environment containing multiple non-communicating agents allowed for the observation of the strategies they developed to maximize individual utility. By testing different environments and different types of agents, global patterns of cooperation and competition emerged. 
	
	Initially, Screeps seemed like a good environment to perform these experiments in. Once we tried to implement Q-learning however, several problems emerged. Because the Screeps world has a fixed amount of time between steps and it is very difficult to save and restore specific board states, it would have taken far too long for any meaningful learning to occur. In addition, the state space is so large that any single state would likely have never been encountered again. Finally, many of the interesting problems such as pathfinding were already solved. 
	
	Because of this, it made the most sense to do this project in a simplified Screeps-like environment without the limitations of a prexisting online game. The goal of a standard agent is to gather resources from a source and bring them back to a spawn. In later environments we narrowed the focus of each agent, dividing them up into gatherers, carriers, and thieves. This allowed us to observe how the agents would act when they were forced to work together and how they would handle threats. By creating this simple clone of Screeps, we obtained more direct control over our experiments. The ability to reload and modify the starting environment and do thousands of episodes of learning in a very short time allowed for the unobstructed observation of the performance of learning methods in a multiagent system. 
	
\section{Prior Research}

\section{Implementation}

\section{Results}

\section{Future Work}

\section{Conclusion}

\section{References}

\end{document}

